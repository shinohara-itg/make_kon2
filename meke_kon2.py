import streamlit as st
import os
from openai import AzureOpenAI
from dotenv import load_dotenv
from io import StringIO
from datetime import datetime
import yaml
import openpyxl
import pandas as pd
from io import BytesIO


# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# Azure OpenAI æ¥ç¶šæƒ…å ±
AZURE_OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = "https://itg-llm-009-aoai-eastus-001.openai.azure.com/"
AZURE_OPENAI_API_VERSION = "2024-02-15-preview"
AZURE_OPENAI_DEPLOYMENT = "itg-llm-009-gpt-4o"

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
st.set_page_config(page_title="å¸‚å ´èª¿æŸ»ä¼ç”»ã‚¢ãƒ—ãƒª", layout="wide")
if "orien_text" not in st.session_state:
    st.session_state.orien_text = ""
if "concept_text" not in st.session_state:
    st.session_state.concept_text = ""
if "storyline_text" not in st.session_state:
    st.session_state.storyline_text = ""



#====================================================================
# ã‚¿ãƒ–æ§‹æˆ
tab1, tab2 = st.tabs(["å¼•åˆæƒ…å ±", "KON"])

# --- ã‚¿ãƒ–1ï¼šã‚ªãƒªã‚¨ãƒ³æƒ…å ±å…¥åŠ› ---
with tab1:
    st.header("ğŸ“ ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆtxtã®ã¿ï¼‰", type=["txt"])

    if uploaded_file is not None:
        content = uploaded_file.read().decode("utf-8")
        st.session_state.orien_text = content
        st.text_area("èª­ã¿è¾¼ã‚“ã å†…å®¹ï¼ˆç·¨é›†å¯ï¼‰", value=content, height=300)

#====================================================================
# --- ã‚¿ãƒ–2ï¼šç”Ÿæˆã¨ç·¨é›† ---
with tab2:
    st.header("âœ¨ ã‚­ãƒƒã‚¯ã‚ªãƒ•ãƒãƒ¼ãƒˆä½œæˆ")

    # --- YAMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–¢æ•° ---
    def load_kon_yaml():
        """
        kon.yaml ã‚’èª­ã¿è¾¼ã‚€ã€‚
        """
        base_dir = os.path.dirname(__file__)
        yaml_path = os.path.join(base_dir, "kon.yaml")
        try:
            with open(yaml_path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            st.error("kon.yaml ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return {}
        except yaml.YAMLError as e:
            st.error(f"YAMLã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return {}

    # YAMLã®èª­ã¿è¾¼ã¿
    kon_prompts = load_kon_yaml()

    # --- è‡ªå‹•ç”Ÿæˆãƒœã‚¿ãƒ³ ---
    if st.session_state.orien_text and kon_prompts and st.button("èª¿æŸ»ä¼ç”»ã‚’ç”Ÿæˆ"):
        with st.spinner("Azure OpenAI ã«å•ã„åˆã‚ã›ä¸­..."):
            try:
                generated_sections = {}

                # --- ä¸Šä½3é …ç›® + ãƒã‚¤ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’ç”Ÿæˆ ---
                for key in ["ãŠå®¢æ§˜å", "èª¿æŸ»å¯¾è±¡ã‚µãƒ¼ãƒ“ã‚¹ã‚„å•†å“å", "ãƒã‚¤ã‚³ãƒ³ã‚»ãƒ—ãƒˆ"]:
                    item = kon_prompts.get(key, {})
                    premise = item.get("å‰æ", "")
                    instruction = item.get("æŒ‡ç¤º", "")
                    format_rule = item.get("å‡ºåŠ›å½¢å¼", "")

                    prompt = f"""
ä»¥ä¸‹ã®ã‚ªãƒªã‚¨ãƒ³æƒ…å ±ã‚’åŸºã«ã€{key}ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚

# å‰æ:
{premise}

# æŒ‡ç¤º:
{instruction}

# å‡ºåŠ›å½¢å¼:
{format_rule}

# ã‚ªãƒªã‚¨ãƒ³æƒ…å ±:
{st.session_state.orien_text}



"""
                    response = client.chat.completions.create(
                        model=AZURE_OPENAI_DEPLOYMENT,
                        messages=[
                            {"role": "system", "content": "ã‚ãªãŸã¯å¸‚å ´èª¿æŸ»ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚"},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.7,
                        max_tokens=500
                    )
                    generated_sections[key] = response.choices[0].message.content.strip()

                # --- ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆ ---
                storyline_prompts = kon_prompts.get("ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ©ã‚¤ãƒ³", {})
                storyline_texts = []
                for idx, (title, instruction) in enumerate(storyline_prompts.items(), start=1):
                    story_prompt = f"""
ä»¥ä¸‹ã®ã‚ªãƒªã‚¨ãƒ³æƒ…å ±ã‚’åŸºã«ã€{title}ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚

# æŒ‡ç¤º:
{instruction}

# ã‚ªãƒªã‚¨ãƒ³æƒ…å ±:
{st.session_state.orien_text}
"""
                    story_response = client.chat.completions.create(
                        model=AZURE_OPENAI_DEPLOYMENT,
                        messages=[
                            {"role": "system", "content": "ã‚ãªãŸã¯å¸‚å ´èª¿æŸ»ã®ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                            {"role": "user", "content": story_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=500
                    )
                    answer = story_response.choices[0].message.content.strip()
                    storyline_texts.append(f"{idx}. {title}\n{answer}\n")

                generated_sections["ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ©ã‚¤ãƒ³"] = "\n".join(storyline_texts)

                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«æ ¼ç´
                st.session_state.generated_sections = generated_sections

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # --- ç·¨é›†å¯èƒ½ã‚¨ãƒªã‚¢ ---
    if "generated_sections" in st.session_state and st.session_state.generated_sections:
        st.subheader("âœï¸ ã‚­ãƒƒã‚¯ã‚ªãƒ•ãƒãƒ¼ãƒˆï¼ˆç·¨é›†å¯ï¼‰")
        edited_sections = {}

        # ä¸Šä½3é …ç›® + ãƒã‚¤ã‚³ãƒ³ã‚»ãƒ—ãƒˆ
        for key in ["ãŠå®¢æ§˜å", "èª¿æŸ»å¯¾è±¡ã‚µãƒ¼ãƒ“ã‚¹ã‚„å•†å“å", "ãƒã‚¤ã‚³ãƒ³ã‚»ãƒ—ãƒˆ"]:
            edited_sections[key] = st.text_area(
                f"ğŸ”¹ {key}", 
                value=st.session_state.generated_sections.get(key, ""), 
                height=80 if key != "ãƒã‚¤ã‚³ãƒ³ã‚»ãƒ—ãƒˆ" else 200
            )

        # ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ©ã‚¤ãƒ³
        edited_sections["ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ©ã‚¤ãƒ³"] = st.text_area(
            "ğŸ“˜ ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ©ã‚¤ãƒ³ï¼ˆç·¨é›†å¯ï¼‰",
            value=st.session_state.generated_sections.get("ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ©ã‚¤ãƒ³", ""),
            height=400
        )

        # --- ä¿å­˜æ©Ÿèƒ½ ---
        # --- ä¿å­˜æ©Ÿèƒ½ ---
        export_content = ""
        for key, value in edited_sections.items():
            export_content += f"ã€{key}ã€‘\n{value}\n\n"

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã¨ã—ã¦åˆ©ç”¨ï¼ˆæŠ¼ã—ãŸã‚‰å³ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
        st.download_button(
            label="ğŸ’¾ ã‚­ãƒƒã‚¯ã‚ªãƒ•ãƒãƒ¼ãƒˆã‚’ä¿å­˜",
            data=export_content,
            file_name=f"èª¿æŸ»ä¼ç”»_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain"
        )

